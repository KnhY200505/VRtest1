<body>
  <!-- Á¨¨‰∏ÄÊ≠•ÔºöÈÄâÊã©Èü≥È¢ëÈ°µÈù¢ -->
  <div id="audio-select-screen" class="screen">
    <h2>üéµ Please select the sound track</h2>
    <div class="btn-container">
      <button onclick="startARWithAudio('AnotherDayOfSun.MP3')">Audio 1</button>
      <button onclick="startARWithAudio('AnotherDayOfSun2.MP3')">Audio 2</button>
      <button onclick="startARWithAudio('AnotherDayOfSun3.MP3')">Audio 3</button>
    </div>
  </div>

  <!-- Á¨¨‰∫åÊ≠•ÔºöAR Âú∫ÊôØ -->
  <a-scene embedded arjs vr-mode-ui="enabled: false" style="display:none" id="ar-scene">
    <a-marker preset="hiro">
      <a-entity id="blendshape-model"
                gltf-model="Cube_Blendshape_test.glb"
                position="0 0 0"
                scale="1 1 1">
      </a-entity>
    </a-marker>
    <a-entity camera></a-entity>
  </a-scene>

  <!-- Êí≠ÊîæÊéßÂà∂ÊåâÈíÆ -->
  <div id="ar-controls" class="screen" style="display: none; background: transparent; z-index: 3;">
    <div class="btn-container">
      <button onclick="togglePlayback()">‚èØÔ∏è Play / Pause</button>
    </div>
  </div>

  <script>
    let modelMesh, analyser, dataArray, audioContext, currentAudio;
    let isPlaying = true;

    function startARWithAudio(filename) {
      document.getElementById('audio-select-screen').style.display = 'none';
      document.getElementById('ar-scene').style.display = 'block';
      document.getElementById('ar-controls').style.display = 'flex';
      playAudio(filename);
    }

    // Ê®°ÂûãÂä†ËΩΩÂêé
    const modelEntity = document.querySelector('#blendshape-model');
    modelEntity.addEventListener('model-loaded', () => {
      const mesh = modelEntity.getObject3D('mesh');
      mesh.traverse(node => {
        if (node.isMesh && node.morphTargetInfluences) {
          modelMesh = node;
        }
      });
    });

    function playAudio(filename) {
      if (currentAudio) currentAudio.pause();
      if (audioContext) audioContext.close();

      currentAudio = new Audio(filename);
      currentAudio.loop = true;
      currentAudio.autoplay = true;

      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const audioSource = audioContext.createMediaElementSource(currentAudio);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 64;
      dataArray = new Uint8Array(analyser.frequencyBinCount);

      audioSource.connect(analyser);
      analyser.connect(audioContext.destination);

      currentAudio.play();
      audioContext.resume();
      isPlaying = true;
      animate();
    }

    function togglePlayback() {
      if (!currentAudio) return;
      if (isPlaying) {
        currentAudio.pause();
        isPlaying = false;
      } else {
        currentAudio.play();
        isPlaying = true;
      }
    }

    function animate() {
      if (!analyser) return;
      requestAnimationFrame(animate);

      analyser.getByteFrequencyData(dataArray);
      const avgFreq = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
      const influence = Math.min(avgFreq / 100, 1);

      if (modelMesh && modelMesh.morphTargetInfluences) {
        modelMesh.morphTargetInfluences[0] = influence;
      }
    }
  </script>
</body>
