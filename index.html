<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AR.js + Blendshape (With Audio Control)</title>
  <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js@3.4.0/aframe/build/aframe-ar.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; font-family: sans-serif; }
    .screen {
      position: absolute;
      width: 100vw;
      height: 100vh;
      background: #111;
      color: white;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      z-index: 5;
    }
    .btn-container button {
      margin: 8px;
      padding: 10px 20px;
      font-size: 16px;
      cursor: pointer;
    }
    /* 播放控制按钮左下角 */
    #ar-controls {
      position: fixed;
      bottom: 16px;
      left: 16px;
      z-index: 10;
    }
    #playPauseBtn {
      position: fixed;
      bottom: 16px;
      left: 16px;
      z-index: 10;
      background: rgba(0,0,0,0.6);
      color: white;
      border: none;
      border-radius: 6px;
      padding: 10px 20px;
      font-size: 16px;
      cursor: pointer;
    }
    /* 返回按钮右下角 */
    #back-btn {
      position: fixed;
      bottom: 16px;
      right: 16px;
      z-index: 10;
      background: rgba(0,0,0,0.6);
      color: white;
      border: none;
      border-radius: 6px;
      padding: 10px 20px;
      font-size: 16px;
      cursor: pointer;
    }
  </style>
</head>
<body>

  <!-- 音频选择页 -->
  <div id="audio-select-screen" class="screen">
    <h2>🎵 Please select the sound track</h2>
    <div class="btn-container">
      <button onclick="startARWithAudio('AnotherDayOfSun.MP3')">Audio 1</button>
      <button onclick="startARWithAudio('AnotherDayOfSun2.MP3')">Audio 2</button>
      <button onclick="startARWithAudio('AnotherDayOfSun3.MP3')">Audio 3</button>
    </div>
  </div>

  <!-- AR.js 场景 -->
  <a-scene embedded arjs vr-mode-ui="enabled: false" style="display:none" id="ar-scene">
    <a-marker preset="hiro">
      <a-entity id="blendshape-model"
                gltf-model="Cube_Blendshape_test.glb"
                position="0 0 0"
                scale="0.5 0.5 0.5">
      </a-entity>
    </a-marker>
    <a-entity camera></a-entity>
  </a-scene>

  <!-- 左下角控制播放按钮 -->
  <div id="ar-controls" style="display: none;">
    <button id="playPauseBtn" onclick="togglePlayback()">Play</button>
  </div>

  <!-- 右下角返回按钮 -->
  <button id="back-btn" style="display: none;" onclick="goBack()">Back</button>

  <script>
    let modelMesh, analyser, dataArray, audioContext, currentAudio;
    let isPlaying = false;
    let audioFile = "";

    function startARWithAudio(filename) {
      document.getElementById('audio-select-screen').style.display = 'none';
      document.getElementById('ar-scene').style.display = 'block';
      document.getElementById('ar-controls').style.display = 'block';
      document.getElementById('back-btn').style.display = 'block';
      audioFile = filename;
      initAudio(filename); // 初始化但默认暂停
    }

    function goBack() {
      // 停止音乐和清除资源
      if (currentAudio) {
        currentAudio.pause();
        currentAudio = null;
      }
      if (audioContext) {
        audioContext.close();
      }
      isPlaying = false;

      // 显示音频选择页，隐藏 AR
      document.getElementById('audio-select-screen').style.display = 'flex';
      document.getElementById('ar-scene').style.display = 'none';
      document.getElementById('ar-controls').style.display = 'none';
      document.getElementById('back-btn').style.display = 'none';

      document.getElementById('playPauseBtn').innerText = 'Play';
    }

    function initAudio(filename) {
      if (currentAudio) currentAudio.pause();
      if (audioContext) audioContext.close();

      currentAudio = new Audio(filename);
      currentAudio.loop = true;

      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const audioSource = audioContext.createMediaElementSource(currentAudio);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 64;
      dataArray = new Uint8Array(analyser.frequencyBinCount);

      audioSource.connect(analyser);
      analyser.connect(audioContext.destination);
    }

    function togglePlayback() {
      if (!currentAudio || !audioContext) return;

      if (!isPlaying) {
        currentAudio.play();
        audioContext.resume();
        isPlaying = true;
        document.getElementById('playPauseBtn').innerText = 'Pause';
        animate();
      } else {
        currentAudio.pause();
        isPlaying = false;
        document.getElementById('playPauseBtn').innerText = 'Play';
      }
    }

    function animate() {
      if (!analyser || !isPlaying) return;
      requestAnimationFrame(animate);

      analyser.getByteFrequencyData(dataArray);
      const avgFreq = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
      const influence = Math.min(avgFreq / 100, 1);

      if (modelMesh && modelMesh.morphTargetInfluences) {
        modelMesh.morphTargetInfluences[0] = influence;
      }
    }

    const modelEntity = document.querySelector('#blendshape-model');
    modelEntity.addEventListener('model-loaded', () => {
      const mesh = modelEntity.getObject3D('mesh');
      mesh.traverse(node => {
        if (node.isMesh && node.morphTargetInfluences) {
          modelMesh = node;
        }
      });
    });
  </script>
</body>
</html>
