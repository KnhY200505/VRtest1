
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AR.js + Blendshape</title>
  <!-- 使用 AR.js 支持的 A-Frame 版本 -->
  <script src="https://aframe.io/releases/0.6.0/aframe.min.js"></script>
  <script src="https://jeromeetienne.github.io/AR.js/aframe/build/aframe-ar.js"></script>
  <style>
    body { margin: 0; overflow: hidden; }
    .btn-container {
      position: absolute;
      top: 10px;
      left: 10px;
      z-index: 2;
    }
    button {
      margin: 4px;
      padding: 6px 12px;
      font-size: 14px;
    }
  </style>
</head>
<body>
  <!-- 控制按钮 -->
  <div class="btn-container">
    <button onclick="playAudio('AnotherDayOfSun.MP3')">Audio 1</button>
    <button onclick="playAudio('AnotherDayOfSun2.MP3')">Audio 2</button>
    <button onclick="playAudio('AnotherDayOfSun3.MP3')">Audio 3</button>
  </div>

  <a-scene embedded arjs>
    <!-- 在 marker 上显示模型 -->
    <a-marker preset="hiro">
      <a-entity id="blendshape-model"
                gltf-model="AnimatedCube.gltf"
                position="0 0 0"
                scale="0.2 0.2 0.2">
      </a-entity>
    </a-marker>

    <a-entity camera></a-entity>
  </a-scene>

  <script>
    let modelMesh, analyser, dataArray, audioContext, currentAudio;

    // 模型加载后获取 mesh
    const modelEntity = document.querySelector('#blendshape-model');
    modelEntity.addEventListener('model-loaded', () => {
      const mesh = modelEntity.getObject3D('mesh');
      mesh.traverse(node => {
        if (node.isMesh && node.morphTargetInfluences) {
          modelMesh = node;
        }
      });
    });

    function playAudio(filename) {
      if (currentAudio) {
        currentAudio.pause();
        currentAudio = null;
      }
      if (audioContext) {
        audioContext.close();
      }

      currentAudio = new Audio(filename);
      currentAudio.loop = true;
      currentAudio.autoplay = true;

      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const audioSource = audioContext.createMediaElementSource(currentAudio);
      analyser = audioContext.createAnalyser();
      analyser.fftSize = 64;
      dataArray = new Uint8Array(analyser.frequencyBinCount);

      audioSource.connect(analyser);
      analyser.connect(audioContext.destination);

      currentAudio.play();
      audioContext.resume();
      animate();
    }

    function animate() {
      if (!analyser) return;
      requestAnimationFrame(animate);

      analyser.getByteFrequencyData(dataArray);
      const avgFreq = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
      const influence = Math.min(avgFreq / 100, 1);

      if (modelMesh && modelMesh.morphTargetInfluences) {
        modelMesh.morphTargetInfluences[0] = influence;
      }
    }
  </script>
</body>
</html>
